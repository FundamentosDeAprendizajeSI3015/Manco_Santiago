# ğŸ“Š Proyecto: Impacto del Uso de IA en la PreparaciÃ³n Laboral

## ğŸ¯ Objetivo

Este proyecto implementa un **pipeline completo de ciencia de datos** para analizar cÃ³mo el uso de herramientas de Inteligencia Artificial influye en la preparaciÃ³n laboral de estudiantes de IngenierÃ­a de Sistemas.

El modelo busca predecir:

> **Â¿Un estudiante estÃ¡ laboralmente preparado? (0 = No, 1 = SÃ­)**

Se trata de un problema de:

* âœ… ClasificaciÃ³n binaria
* âœ… Aprendizaje supervisado
* âœ… Dataset estructurado

---

# 1ï¸âƒ£ DefiniciÃ³n del Problema

Se define formalmente el problema en un archivo:

```
data_output_educacion_ia/definicion_problema.json
```

Contiene:

* Objetivo
* Impacto
* Tipo de problema
* Variables numÃ©ricas
* Variables categÃ³ricas
* Variables binarias

### Variables utilizadas

#### Variables NumÃ©ricas

* promedio_acumulado
* nota_algoritmos
* nota_bases_datos
* horas_estudio_semana

#### Variables CategÃ³ricas

* frecuencia_uso_ia
* dependencia_ia
* aprendizaje_activo

#### Variables Binarias

* uso_para_codigo
* uso_para_teoria
* proyectos_personales

---

# 2ï¸âƒ£ Carga y RecolecciÃ³n de Datos

El dataset:

```python
dataset_ingenieria_sistemas_ia_300_realista.csv
```

Se analiza:

* DimensiÃ³n del dataset
* Tipos de datos
* Valores nulos
* DistribuciÃ³n del target

Esto permite verificar:

* Calidad de los datos
* Balance de clases
* Posibles problemas estructurales

---

# 3ï¸âƒ£ AnÃ¡lisis Exploratorio de Datos (EDA)

Se realiza un anÃ¡lisis estadÃ­stico completo:

---

## Tendencia Central

Para variables numÃ©ricas:

* Media
* Mediana
* Moda

Archivo generado:

```
tendencia_central_numericas.csv
```

Para variables binarias:

```
tendencia_central_binarias.csv
```

Para categÃ³ricas:

```
moda_categoricas.json
```

---

## Cuartiles e IQR

Se calcula:

* Q1
* Q3
* IQR (Rango IntercuartÃ­lico)

Archivo:

```
iqr_results.json
```

---

## Percentiles

Se calculan:

* P10
* P50
* P90

Archivo:

```
percentiles.json
```

---

## Correlaciones

Se genera:

* Matriz de correlaciÃ³n
* Heatmap visual
* CorrelaciÃ³n Pearson
* CorrelaciÃ³n Spearman

Archivo generado:

```
heatmap_correlacion.png
correlation_stats.json
```

Esto permite entender:

* QuÃ© variables impactan mÃ¡s el target
* Relaciones lineales vs monotÃ³nicas

---

## Tabla DinÃ¡mica (Pivot Table)

Se analiza el promedio acumulado segÃºn frecuencia de uso de IA y preparaciÃ³n laboral.

Archivo:

```
pivot_promedio_por_frecuencia.csv
```

---

## Visualizaciones Interactivas

Se generan grÃ¡ficos en HTML interactivos:

### Scatter Matrix

```
interactive_scatter_matrix.html
```

### GrÃ¡fico 3D

```
interactive_scatter_3d.html
```

### UMAP 2D

```
interactive_umap_2d.html
```

### UMAP 3D

```
interactive_umap_3d.html
```

UMAP permite visualizar separabilidad entre clases en espacios reducidos.

---

# 4ï¸âƒ£ Procesamiento de Datos

Se realiza:

### Limpieza

* ConversiÃ³n segura a numÃ©rico
* ImputaciÃ³n con mediana (numÃ©ricas)
* Relleno "**MISSING**" (categÃ³ricas)

### One-Hot Encoding

Se aplica:

```python
pd.get_dummies(..., drop_first=True)
```

Para evitar multicolinealidad (Dummy Trap).

---

# 5ï¸âƒ£ DivisiÃ³n del Dataset

Se aplica:

```
70% Train
15% Validation
15% Test
```

Con:

```python
stratify=y
```

Esto garantiza que la proporciÃ³n de clases se mantenga en todos los splits.

---

# âš–ï¸ Balanceo de Clases (Solo Train)

Se utiliza:

```python
resample()
```

* Se iguala el tamaÃ±o de la clase minoritaria
* Se evita que el modelo se sesgue

Importante:
El balanceo **solo se aplica en entrenamiento**, nunca en validaciÃ³n o test.

---

# ğŸ“ Escalado

Se usa:

```python
StandardScaler()
```

* Fit en train
* Transform en val y test

Esto evita data leakage.

---

# 6ï¸âƒ£ ExportaciÃ³n Final

Se exportan:

```
X_train.parquet
X_val.parquet
X_test.parquet

y_train.parquet
y_val.parquet
y_test.parquet
```

AdemÃ¡s:

```
processed_schema.json
```

Contiene:

* ProporciÃ³n de split
* Balance final de clases

---

# ğŸ“‚ Estructura de Carpetas

```
data_output_educacion_ia/
â”‚
â”œâ”€â”€ definicion_problema.json
â”œâ”€â”€ tendencia_central_numericas.csv
â”œâ”€â”€ tendencia_central_binarias.csv
â”œâ”€â”€ moda_categoricas.json
â”œâ”€â”€ iqr_results.json
â”œâ”€â”€ percentiles.json
â”œâ”€â”€ correlation_stats.json
â”œâ”€â”€ heatmap_correlacion.png
â”œâ”€â”€ pivot_promedio_por_frecuencia.csv
â”œâ”€â”€ interactive_scatter_matrix.html
â”œâ”€â”€ interactive_scatter_3d.html
â”œâ”€â”€ interactive_umap_2d.html
â”œâ”€â”€ interactive_umap_3d.html
â”œâ”€â”€ X_train.parquet
â”œâ”€â”€ X_val.parquet
â”œâ”€â”€ X_test.parquet
â”œâ”€â”€ y_train.parquet
â”œâ”€â”€ y_val.parquet
â”œâ”€â”€ y_test.parquet
â””â”€â”€ processed_schema.json
```

---

# Buenas PrÃ¡cticas Implementadas

âœ” SeparaciÃ³n clara de fases
âœ” No hay data leakage
âœ” Balanceo solo en entrenamiento
âœ” EstratificaciÃ³n en split
âœ” Escalado correcto
âœ” ExportaciÃ³n reproducible
âœ” EDA documentado
âœ” Visualizaciones interactivas
